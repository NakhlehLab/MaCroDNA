{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clone Generation\n",
    "In this script, we elaborated the detail process for getting clones from the data. As mentioned in the paper, our aim was to mitigate the influence of clones on integration accuracy. Therefore, we employed two different clustering methods, namely agglomerative clustering, and intNMF. For each clustering method, we used either untransformed or log-transformed data to obtain the clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "from scanpy.pp import log1p\n",
    "import os\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T07:05:12.462004811Z",
     "start_time": "2023-07-01T07:05:12.413668352Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data preparation\n",
    "Here, we use two strategies: clustering on the original CNA data and clustering on the log-transformed CNAs. The CNA data can have an extremely right-skewed distribution. Thus, $\\log (x + 1) $ was applied, where $x$ is the original copy number."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# read data as dataframe\n",
    "DataDir = \"Data/\"\n",
    "dna = pd.read_csv(DataDir+\"cnv_raw.csv\",index_col=0)\n",
    "\n",
    "ClusterDir = \"Cluster/\"\n",
    "if not os.path.isdir(ClusterDir):\n",
    "    os.mkdir(ClusterDir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T07:18:43.336683392Z",
     "start_time": "2023-07-01T07:18:43.265272027Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 untransformed CNA data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "ClusterDataDir = ClusterDir + \"cluster_data/\"\n",
    "if not os.path.isdir(ClusterDataDir):\n",
    "    os.mkdir(ClusterDataDir)\n",
    "\n",
    "dna_untran = dna\n",
    "dna_untran.to_csv(ClusterDataDir + \"dna_untransformed.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T07:18:44.661564657Z",
     "start_time": "2023-07-01T07:18:44.307177298Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 log-transformed CNA data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def log_transform(df):\n",
    "    # scanpy.pp.log1p needs n_obs Ã— n_vars\n",
    "    return pd.DataFrame(log1p(df.to_numpy().T).T,\n",
    "                        index=list(df.index),columns=list(df.columns))\n",
    "\n",
    "dna_log = log_transform(dna)\n",
    "dna_log.to_csv(ClusterDataDir + \"dna_log.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T07:18:46.467909902Z",
     "start_time": "2023-07-01T07:18:45.446455222Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Clustering\n",
    "We applied to methods for getting clusters, [agglomerative clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) and [intNMF](https://pubmed.ncbi.nlm.nih.gov/28459819/). For each method, we identified clusters from untransformed data and log-transformed data separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Agglomerative clustering\n",
    "\n",
    "Given the difficulty of determining the optimal number of clusters using agglomerative clustering alone, we adopted a multi-resolution approach. By constructing clusters at different levels of resolution, we aimed to mitigate the influence of cluster numbers and obtain a more comprehensive understanding of the data.\n",
    "\n",
    "Specifically, we initially obtained four clusters from the dataset. Then, we proceeded to iteratively merge similar clusters until we reached a point where only two clusters remained."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# specify the initial cluster number\n",
    "cluster_num = 4\n",
    "\n",
    "# agglomerative clusters using untransformed data\n",
    "utils.cluster_and_merge(dna_untran, cluster_num, ClusterDir+\"agg_cluster_untransformed/\")\n",
    "# agglomerative clusters using log-transformed data\n",
    "utils.cluster_and_merge(dna_log, cluster_num, ClusterDir+\"agg_cluster_log/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T05:53:04.226403963Z",
     "start_time": "2023-07-01T05:53:03.610015051Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 intNMF\n",
    "\n",
    "intNMF can find the optimal cluster numbers, so there is no need to do merging, the code is in run_IntNMF.R"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
